# プロトタイプ計画（LLM込み）

## 0) 目的の定義（半日）
- 出力JSON仕様を確定
- 必須項目を決める（例：車名/年式/走行距離）

## 1) データ収集（1〜2日）
- 50〜200枚の出品表画像
- `data/raw/` に保存

## 2) Azure OCR で文字＋bbox取得（1〜2日）
- OCRで文字と位置情報（bbox）を取得
- 用語: OCR = 画像から文字を読むAI

## 3) YOLOで車体図検出（3〜5日）
- 車体図を四角で囲むラベル付け
- 1クラス検出モデルを学習
- 用語: bbox = 画像内の四角い枠の座標

## 4) LLMでキー・バリュー抽出（1〜2日）
- OCR結果をLLMに渡して項目の意味づけ
- 用語: LLM = 大規模言語モデル

## 5) LLM後処理（半日）
- 表記ゆれ補正（例: 8,828KM → 8828）
- 形式統一（年式/距離/排気量など）

## 6) 統合JSON生成（1日）
- OCRのbbox + LLMの項目抽出 + YOLOの図bbox を統合
- 仕様通りのJSONを出力

## 7) 評価（2日）
- OCR精度（文字一致）
- K/V精度（キーと値の一致率）
- bbox精度（IoU）
- 速度（1画像あたりの平均処理時間）
- コスト（1画像あたりのAPI費用）
